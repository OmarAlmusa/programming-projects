{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce0050e1-af3e-4eac-af26-2a72e76a7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148341e8-71a6-4d06-adf6-afdc9635bcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video_footages\\\\Raw Video_ Pittsburg Neighborhood Drive-By Shootings.mp4',\n",
       " 'video_footages\\\\Road traffic video for object recognition.mp4',\n",
       " 'video_footages\\\\Shooting captured by surveillance camera in Parma.mp4',\n",
       " 'video_footages\\\\Shopping, People, Commerce, Mall, Many, Crowd, Walking   Free Stock video footage   YouTube.mp4',\n",
       " 'video_footages\\\\Traffic Flow In The Highway - 4K Stock Videos _ NoCopyright _ AllVideoFree.mp4',\n",
       " 'video_footages\\\\vecteezy_busy-street-in-evening-hong-kong_28840705 (1) (1).mp4',\n",
       " 'video_footages\\\\vecteezy_people-crossing-the-road-on-zebra-tallin_28257759.mp4']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_files = glob.glob('video_footages/*')\n",
    "video_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b3b27c-3290-4c28-8de2-f28e78fb8b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images\\\\test.png',\n",
       " 'images\\\\woman1.jpg',\n",
       " 'images\\\\woman2.jpg',\n",
       " 'images\\\\woman3.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_files = glob.glob('images/*')\n",
    "image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0edf786e-5bd8-4195-8f05-a6426fda716d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97, 207, 165, 62, 10230], [98, 208, 163, 60, 9780], [503, 199, 62, 154, 9548], [504, 200, 60, 152, 9120], [703, 91, 82, 160, 13120], [704, 92, 80, 158, 12640], [310, 51, 174, 141, 24534], [311, 53, 172, 138, 23736]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(image_files[0])\n",
    "height, width, layers = img.shape\n",
    "new_height = height/2\n",
    "new_width = width/2\n",
    "img = cv2.resize(img, (int(new_width), int(new_height)))\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "contours, _ = cv2.findContours(gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "boxes = []\n",
    "for cnt in contours:\n",
    "    [x, y, w, h] = cv2.boundingRect(cnt)\n",
    "    area = w*h\n",
    "    img = cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "    boxes.append([x,y,w,h, area])\n",
    "print(boxes)\n",
    "cv2.imshow('test', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a6b5cc9e-fc18-4e09-97f5-390f5397c8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[311, 53, 172, 138, 23736], [310, 51, 174, 141, 24534]]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms(boxes, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "388b0740-9df5-4d01-810c-39a14a650ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\"\n",
    "    the boxes should be in format of (x, y, w, h, area)\n",
    "    \"\"\"\n",
    "    xx = max(box1[0],box2[0])\n",
    "    yy = max(box1[1],box2[1])\n",
    "    xf = min(box1[0]+box1[2],box2[0]+box2[2])\n",
    "    yf = min(box1[1]+box1[3],box2[1]+box2[3])\n",
    "    area1 = box1[2]*box1[3]\n",
    "    area2 = box2[2]*box2[3]\n",
    "\n",
    "    w = max(0, xf-xx)\n",
    "    h = max(0, yf-yy)\n",
    "\n",
    "    intersection = w*h\n",
    "    union = abs(area1) + abs(area2) - intersection + 1e-6\n",
    "    result = intersection/union\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "edc8ece8-a51a-4667-a089-1c0339d77ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9560117301118268"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou(boxes[0], boxes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25d192c9-c7f9-4cf0-a7da-bb786f15e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.array([[1, 3, 2 ,3 ,0.26],\n",
    "                       [2, 3, 3, 2, 0.98],\n",
    "                       [-2, 0, 2, 1, 0.54],\n",
    "                       [6, 2, 4, 2, 0.92]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f9ba768-03db-474a-a30a-a58236d14aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.0, 3.0, 3.0, 2.0, 0.98], [6.0, 2.0, 4.0, 2.0, 0.92]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms(test_array.tolist(), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eacd428a-1755-4fc5-8854-64b98be82e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(bboxes, threshold):\n",
    "    assert type(bboxes) == list\n",
    "    bboxes = [box for box in bboxes if box[-1] > threshold]\n",
    "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
    "    bboxes_after_nms = []\n",
    "    while bboxes:\n",
    "        chosen_box = bboxes.pop(0)\n",
    "\n",
    "        bboxes = [box for box in bboxes if iou(chosen_box[:4],box[:4])< threshold]\n",
    "\n",
    "        bboxes_after_nms.append(chosen_box)\n",
    "\n",
    "    return bboxes_after_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "55b30042-8470-406b-9ea6-c8d4307877e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motion_mask(fg_mask, min_thresh=0, kernel=np.array((9,9), dtype=np.uint8)):\n",
    "    \"\"\" Obtains image mask\n",
    "        Inputs: \n",
    "            fg_mask - foreground mask\n",
    "            kernel - kernel for Morphological Operations\n",
    "        Outputs: \n",
    "            mask - Thresholded mask for moving pixels\n",
    "        \"\"\"\n",
    "    _, thresh = cv2.threshold(fg_mask,min_thresh,255,cv2.THRESH_BINARY)\n",
    "    motion_mask = cv2.medianBlur(thresh, 3)\n",
    "    \n",
    "    # morphological operations\n",
    "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    return motion_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dea32e0a-a66f-43f1-a567-1e1a4bfa63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'MOG2' # 'KNN'\n",
    "\n",
    "\n",
    "if sub_type == 'MOG2':\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2(varThreshold=16, detectShadows=False)\n",
    "else:\n",
    "    backSub = cv2.createBackgroundSubtractorKNN(dist2Threshold=1000, detectShadows=False)\n",
    "\n",
    "\n",
    "thresh = 700\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video_files[6])\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "      \n",
    "        height, width, layers = frame.shape\n",
    "        new_h = height / 2\n",
    "        new_w = width / 2\n",
    "        frame = cv2.resize(frame, (int(new_w), int(new_h)))\n",
    "        fgMask = backSub.apply(frame)\n",
    "        motion_mask = get_motion_mask(fgMask, min_thresh=127)\n",
    "\n",
    "        contours, _ = cv2.findContours(motion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)\n",
    "\n",
    "        predictions = []\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            area = w*h\n",
    "            predictions.append([x,y,w,h,area])\n",
    "        predictions = nms(predictions, thresh)\n",
    "        for box in predictions:\n",
    "            #if box[-1] > thresh:\n",
    "            frame = cv2.rectangle(frame, (box[0], box[1]), (box[0]+box[2], box[1]+box[3]), (0, 255, 0), thickness = 2)\n",
    "\n",
    "\n",
    "        cv2.imshow('normal video',frame)\n",
    "        cv2.imshow('fg_mask',motion_mask)\n",
    "\n",
    "    \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70154be-eab1-4fa6-bdcf-fb2533c8beea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
