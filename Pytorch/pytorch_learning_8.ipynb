{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:\\\\Users\\\\An_asus\\\\Desktop\\\\Programming\\\\JupyterNotebook\\\\pytorch\\\\data'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\An_asus\\\\Desktop\\\\Programming\\\\JupyterNotebook\\\\pytorch\\\\data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=(3, 3), padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16, 8, kernel_size=(3, 3), padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(8 * 8 * 8, 32),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(32, 2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An_asus\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0619, -0.1190]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(3, 3), padding=1)\n",
    "        self.act = nn.Tanh()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=(3, 3), padding=1)\n",
    "        self.fc1 = nn.Linear(8*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        x = self.pool(self.act(self.conv1(t)))\n",
    "        x = self.pool(self.act(self.conv2(x)))\n",
    "        x = x.view(-1, 8*8*8)\n",
    "        x = self.act(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=(3, 3), padding=1)\n",
    "        self.fc1 = nn.Linear(8*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        x = F.max_pool2d(F.tanh(self.conv1(t)), 2)\n",
    "        x = F.max_pool2d(F.tanh(self.conv2(x)), 2)\n",
    "        with torch.no_grad():\n",
    "            fst_linear_shape = torch.prod(torch.tensor(x.shape[1:]))\n",
    "        x = x.view(-1, fst_linear_shape)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            \n",
    "            imgs = imgs.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            \n",
    "            t_p = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(t_p, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "            datetime.datetime.now(), epoch,\n",
    "            loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-08 03:53:42.327656 Epoch 1, Training loss 0.561052217415184\n",
      "2021-09-08 03:53:47.080010 Epoch 10, Training loss 0.34501009553101414\n",
      "2021-09-08 03:53:52.549418 Epoch 20, Training loss 0.30996516289984344\n",
      "2021-09-08 03:53:58.326850 Epoch 30, Training loss 0.28421573312419235\n",
      "2021-09-08 03:54:03.846189 Epoch 40, Training loss 0.25976174785073397\n",
      "2021-09-08 03:54:09.401607 Epoch 50, Training loss 0.23997293687929774\n",
      "2021-09-08 03:54:15.328046 Epoch 60, Training loss 0.2207812497949904\n",
      "2021-09-08 03:54:20.923464 Epoch 70, Training loss 0.2029385419598051\n",
      "2021-09-08 03:54:26.641892 Epoch 80, Training loss 0.187341618547394\n",
      "2021-09-08 03:54:32.342875 Epoch 90, Training loss 0.17050105693993295\n",
      "2021-09-08 03:54:37.954296 Epoch 100, Training loss 0.15981064658540828\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs = 100,\n",
    "              optimizer = optimizer,\n",
    "              model = model,\n",
    "              loss_fn = loss_fn,\n",
    "              train_loader= train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_test = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size= 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, train_loader_test, val_loader):\n",
    "    for name, loader in [('train', train_loader_test), ('val', val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "                \n",
    "                t_p = model(imgs)\n",
    "                \n",
    "                _, predicted = torch.max(t_p, dim=1)\n",
    "                \n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "            \n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.94\n",
      "Accuracy val: 0.88\n"
     ]
    }
   ],
   "source": [
    "validate(model, train_loader_test, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\An_asus\\\\Desktop\\\\Programming\\\\JupyterNotebook\\\\pytorch'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('pytorch_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('pytorch_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = 'C:\\\\Users\\\\An_asus\\\\Desktop\\\\Programming\\\\JupyterNotebook\\\\pytorch\\\\pytorch_models\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), saved_model_path + 'birds_vs_planes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\An_asus\\\\Desktop\\\\Programming\\\\JupyterNotebook\\\\pytorch\\\\pytorch_models\\\\'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load(saved_model_path + 'birds_vs_planes.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            \n",
    "            imgs = imgs.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            \n",
    "            t_p = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(t_p, labels)\n",
    "            \n",
    "            l2_lambda = 0.001\n",
    "            \n",
    "            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "            \n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An_asus\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-08 03:57:40.018954 Epoch 1, Training loss 0.5769738627087538\n",
      "2021-09-08 03:57:46.423431 Epoch 10, Training loss 0.3598576806912756\n",
      "2021-09-08 03:57:53.534963 Epoch 20, Training loss 0.32333577685295395\n",
      "2021-09-08 03:58:01.142527 Epoch 30, Training loss 0.29841613399375017\n",
      "2021-09-08 03:58:08.569085 Epoch 40, Training loss 0.281171115720348\n",
      "2021-09-08 03:58:16.388664 Epoch 50, Training loss 0.2649215316506708\n",
      "2021-09-08 03:58:24.038233 Epoch 60, Training loss 0.2519856596448619\n",
      "2021-09-08 03:58:31.878818 Epoch 70, Training loss 0.240795052450174\n",
      "2021-09-08 03:58:39.535390 Epoch 80, Training loss 0.2331613962817344\n",
      "2021-09-08 03:58:47.421459 Epoch 90, Training loss 0.2234895055176346\n",
      "2021-09-08 03:58:55.127032 Epoch 100, Training loss 0.21384811724067493\n"
     ]
    }
   ],
   "source": [
    "training_loop_l2reg(n_epochs = 100,\n",
    "                      optimizer = optimizer,\n",
    "                      model = model,\n",
    "                      loss_fn = loss_fn,\n",
    "                      train_loader= train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.92\n",
      "Accuracy val: 0.89\n"
     ]
    }
   ],
   "source": [
    "validate(model, train_loader_test, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n_chans=32):\n",
    "        super(NetDropout, self).__init__()\n",
    "        self.n_chans = n_chans\n",
    "        self.conv1 = nn.Conv2d(3, n_chans, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans, n_chans // 2, kernel_size=(3, 3), padding=1)\n",
    "        self.convdropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        x = F.max_pool2d(F.tanh(self.conv1(t)), 2)\n",
    "        x = self.convdropout(x)\n",
    "        x = F.max_pool2d(F.tanh(self.conv2(x)), 2)\n",
    "        x = self.convdropout(x)\n",
    "        \n",
    "        x = x.view(-1, 8 * 8 * self.n_chans // 2)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop = NetDropout().to('cuda')\n",
    "\n",
    "optimizer = optim.SGD(model_drop.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-08 04:09:53.686455 Epoch 1, Training loss 0.5670157640602937\n",
      "2021-09-08 04:10:00.078931 Epoch 10, Training loss 0.3752840326470175\n",
      "2021-09-08 04:10:06.851631 Epoch 20, Training loss 0.34575967576093736\n",
      "2021-09-08 04:10:13.818150 Epoch 30, Training loss 0.32157994711854654\n",
      "2021-09-08 04:10:20.572653 Epoch 40, Training loss 0.3106063318670176\n",
      "2021-09-08 04:10:27.547172 Epoch 50, Training loss 0.2907200011478108\n",
      "2021-09-08 04:10:34.243378 Epoch 60, Training loss 0.2771661716281988\n",
      "2021-09-08 04:10:40.896874 Epoch 70, Training loss 0.2659934281258826\n",
      "2021-09-08 04:10:47.761151 Epoch 80, Training loss 0.25956444736498935\n",
      "2021-09-08 04:10:54.590658 Epoch 90, Training loss 0.2458324297598213\n",
      "2021-09-08 04:11:01.575187 Epoch 100, Training loss 0.23956219785532373\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs=100,\n",
    "              optimizer=optimizer,\n",
    "              loss_fn=loss_fn,\n",
    "              model= model_drop,\n",
    "              train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An_asus\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.91\n",
      "Accuracy val: 0.87\n"
     ]
    }
   ],
   "source": [
    "validate(model_drop, train_loader_test, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An_asus\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-08 04:11:36.151785 Epoch 1, Training loss 0.6052124557221771\n",
      "2021-09-08 04:11:44.042586 Epoch 10, Training loss 0.4036009721695238\n",
      "2021-09-08 04:11:52.829241 Epoch 20, Training loss 0.3788613119892254\n",
      "2021-09-08 04:12:01.395879 Epoch 30, Training loss 0.35749595654997857\n",
      "2021-09-08 04:12:10.049726 Epoch 40, Training loss 0.34335598529903755\n",
      "2021-09-08 04:12:18.652366 Epoch 50, Training loss 0.3282385178052696\n",
      "2021-09-08 04:12:27.218673 Epoch 60, Training loss 0.3173913386217348\n",
      "2021-09-08 04:12:35.801713 Epoch 70, Training loss 0.3067009375922999\n",
      "2021-09-08 04:12:44.230343 Epoch 80, Training loss 0.30013750768770836\n",
      "2021-09-08 04:12:52.939273 Epoch 90, Training loss 0.28894850013742024\n",
      "2021-09-08 04:13:01.534760 Epoch 100, Training loss 0.2805487247788982\n"
     ]
    }
   ],
   "source": [
    "training_loop_l2reg(n_epochs=100,\n",
    "              optimizer=optimizer,\n",
    "              loss_fn=loss_fn,\n",
    "              model= model_drop,\n",
    "              train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.90\n",
      "Accuracy val: 0.88\n"
     ]
    }
   ],
   "source": [
    "validate(model_drop, train_loader_test, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetBatchNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_chans =32):\n",
    "        super(NetBatchNorm, self).__init__()\n",
    "        \n",
    "        self.n_chans = n_chans\n",
    "        self.conv1 = nn.Conv2d(3, n_chans, kernel_size=(3, 3), padding=1)\n",
    "        self.bn_conv1 = nn.BatchNorm2d(num_features=n_chans)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(n_chans, n_chans // 2, kernel_size=(3, 3), padding=1)\n",
    "        self.bn_conv2 = nn.BatchNorm2d(num_features=n_chans // 2)\n",
    "        self.fc1 = nn.Linear(8*8*n_chans // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        x = self.bn_conv1(self.conv1(t))\n",
    "        x = F.max_pool2d(torch.tanh(x), 2)\n",
    "        \n",
    "        x = self.bn_conv2(self.conv2(x))\n",
    "        x = F.max_pool2d(torch.tanh(x), 2)\n",
    "        \n",
    "        x = x.view(-1, 8*8*self.n_chans // 2)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn = NetBatchNorm().to('cuda')\n",
    "\n",
    "optimizer = optim.SGD(model_bn.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-08 04:23:02.177380 Epoch 1, Training loss 0.4543456488354191\n",
      "2021-09-08 04:23:09.241832 Epoch 10, Training loss 0.26876255936303717\n",
      "2021-09-08 04:23:17.215428 Epoch 20, Training loss 0.21226825019356552\n",
      "2021-09-08 04:23:25.031009 Epoch 30, Training loss 0.16525772854590873\n",
      "2021-09-08 04:23:33.043607 Epoch 40, Training loss 0.1305396316489976\n",
      "2021-09-08 04:23:41.046979 Epoch 50, Training loss 0.10075461850234657\n",
      "2021-09-08 04:23:49.033572 Epoch 60, Training loss 0.07316335196944938\n",
      "2021-09-08 04:23:56.957580 Epoch 70, Training loss 0.05464557723207458\n",
      "2021-09-08 04:24:04.938175 Epoch 80, Training loss 0.036121688617073044\n",
      "2021-09-08 04:24:12.951649 Epoch 90, Training loss 0.03295332788946522\n",
      "2021-09-08 04:24:20.924244 Epoch 100, Training loss 0.02031807359426644\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs=100,\n",
    "              optimizer=optimizer,\n",
    "              loss_fn=loss_fn,\n",
    "              model= model_bn,\n",
    "              train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.94\n",
      "Accuracy val: 0.84\n"
     ]
    }
   ],
   "source": [
    "validate(model_bn, train_loader_test, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-08 04:25:14.316469 Epoch 1, Training loss 0.5191393557247842\n",
      "2021-09-08 04:25:23.910185 Epoch 10, Training loss 0.3422966164768122\n",
      "2021-09-08 04:25:34.232954 Epoch 20, Training loss 0.283682864562721\n",
      "2021-09-08 04:25:44.984756 Epoch 30, Training loss 0.24546698580501944\n",
      "2021-09-08 04:25:54.887493 Epoch 40, Training loss 0.21193236720030476\n",
      "2021-09-08 04:26:04.878237 Epoch 50, Training loss 0.18048901006484488\n",
      "2021-09-08 04:26:14.775973 Epoch 60, Training loss 0.16471033775882357\n",
      "2021-09-08 04:26:24.391568 Epoch 70, Training loss 0.14520732731006708\n",
      "2021-09-08 04:26:34.137296 Epoch 80, Training loss 0.13520758494639853\n",
      "2021-09-08 04:26:44.555774 Epoch 90, Training loss 0.12072904597801767\n",
      "2021-09-08 04:26:54.183395 Epoch 100, Training loss 0.1107212676648881\n"
     ]
    }
   ],
   "source": [
    "training_loop_l2reg(n_epochs=100,\n",
    "                  optimizer=optimizer,\n",
    "                  loss_fn=loss_fn,\n",
    "                  model= model_bn,\n",
    "                  train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.99\n",
      "Accuracy val: 0.89\n"
     ]
    }
   ],
   "source": [
    "validate(model_bn, train_loader_test, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDepth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "        padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "        kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    def forward(self, t):\n",
    "        x1 = F.max_pool2d(torch.relu(self.conv1(t)), 2)\n",
    "        x = F.max_pool2d(torch.relu(self.conv2(x1)), 2)\n",
    "        x = F.max_pool2d(torch.relu(self.conv3(x + x1)), 2)\n",
    "        \n",
    "        x = x.view(-1, 4*4* self.n_chans1 // 2)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=(3, 3), padding=1)\n",
    "        self.bn = nn.BatchNorm2d(num_features=n_chans)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        x = torch.relu(self.bn(self.conv(t)))\n",
    "        return x + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1 = 32, n_blocks = 10):\n",
    "        super(NetResDeep, self).__init__()\n",
    "        \n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=(3, 3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=n_chans1)\n",
    "        \n",
    "        self.resblocks = nn.Sequential( * (n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        \n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        x = self.bn1(self.conv1(t))\n",
    "        x = F.max_pool2d(torch.relu(x), 2)\n",
    "        x = self.resblocks(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 8*8*self.n_chans1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-08 04:59:01.476997 Epoch 1, Training loss 0.608213076545934\n",
      "2021-09-08 04:59:14.496821 Epoch 10, Training loss 0.27595854688222243\n",
      "2021-09-08 04:59:28.394856 Epoch 20, Training loss 0.2313645642938887\n",
      "2021-09-08 04:59:42.652776 Epoch 30, Training loss 0.20794062767249005\n",
      "2021-09-08 04:59:56.827831 Epoch 40, Training loss 0.1962177941848518\n",
      "2021-09-08 05:00:11.599387 Epoch 50, Training loss 0.18170336871200307\n"
     ]
    }
   ],
   "source": [
    "res_model = NetResDeep(n_chans1 = 16, n_blocks=5).to('cuda')\n",
    "\n",
    "res_optimizer = optim.Adam(res_model.parameters(), lr=3e-3)\n",
    "\n",
    "training_loop_l2reg(n_epochs=50, \n",
    "                    optimizer = res_optimizer, \n",
    "                    model = res_model, \n",
    "                    loss_fn=loss_fn,\n",
    "                    train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.96\n",
      "Accuracy val: 0.91\n"
     ]
    }
   ],
   "source": [
    "validate(res_model, train_loader_test, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(res_model.state_dict(), saved_model_path + 'ResNet_plane vs bird.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
