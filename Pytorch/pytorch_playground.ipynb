{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(data_path, train=True, download = True, \n",
    "                              transform =  transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_data = datasets.CIFAR10(data_path, train=False, download = True, \n",
    "                              transform =  transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.bn = nn.BatchNorm2d(num_features=32)\n",
    "        self.fc1 = nn.Linear(32*4*4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.bn(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.relu(out), 2)\n",
    "        out = self.bn(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.relu(out), 2)\n",
    "        out = self.bn(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.relu(out), 2)\n",
    "        out = out.reshape(-1, 32*4*4)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        return self.fc2(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 9, 8, 4, 2, 9, 5, 1, 2, 8, 1, 2, 1, 2, 5, 1, 2, 3, 5, 7, 1, 2, 5,\n",
       "        5, 9, 3, 5, 1, 3, 1, 2, 1, 8, 4, 7, 8, 5, 3, 2, 5, 9, 9, 9, 8, 9, 4, 4,\n",
       "        7, 7, 4, 5, 0, 5, 4, 9, 9, 9, 9, 3, 0, 5, 6, 1], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, preds = torch.max(model(img.to('cuda')), dim=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(53, device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == label.to('cuda')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_sum = 0.0\n",
    "        num_samples = 0.0\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            \n",
    "            scores = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(scores, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_sum += loss.item()\n",
    "            num_samples += labels.size(0)\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f'epoch: {epoch} \\t loss: {loss_sum/num_samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \t loss: 0.02317188651561737\n",
      "epoch: 5 \t loss: 0.013153576763868332\n",
      "epoch: 10 \t loss: 0.01128093208372593\n",
      "epoch: 15 \t loss: 0.010249423859119415\n",
      "epoch: 20 \t loss: 0.00948134977698326\n",
      "epoch: 25 \t loss: 0.009088031480312347\n",
      "epoch: 30 \t loss: 0.008768470445275307\n",
      "epoch: 35 \t loss: 0.00837251791447401\n",
      "epoch: 40 \t loss: 0.008123035531938076\n",
      "epoch: 45 \t loss: 0.007983841491937637\n",
      "epoch: 50 \t loss: 0.007764490563571453\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop(n_epochs = 50,\n",
    "              optimizer = optimizer,\n",
    "              model = model,\n",
    "              loss_fn = loss_fn,\n",
    "              train_loader= train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, test_loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    for imgs, labels in test_loader:\n",
    "        \n",
    "        imgs = imgs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        _, preds = torch.max(model(imgs), dim=1)\n",
    "        \n",
    "        num_correct += (preds == labels).sum()\n",
    "        num_samples += labels.size(0)\n",
    "    print(f\"correct_predictions: {num_correct} / {num_samples} \\t accuracy: {float(num_correct/num_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_predictions: 7086 / 10000 \t accuracy: 0.7085999846458435\n"
     ]
    }
   ],
   "source": [
    "test_loop(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResDense(nn.Module):\n",
    "    def __init__(self, neurons):\n",
    "        super(ResDense, self).__init__()\n",
    "        \n",
    "        self.dense = nn.Linear(neurons, neurons)\n",
    "        self.bn = nn.BatchNorm1d(neurons)\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(filters, filters, kernel_size=(5, 5), padding=2)\n",
    "        self.bn = nn.BatchNorm2d(num_features=filters)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn(self.conv(x)))\n",
    "        return (out + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_filters, num_blocks):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.num_filters = num_filters\n",
    "        self.conv1 = nn.Conv2d(3, num_filters, kernel_size=(5, 5), padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=num_filters)\n",
    "        self.res = nn.Sequential( * ( num_blocks * [ResBlock(num_filters)]))\n",
    "        \n",
    "        self.conv_memory = nn.Conv2d(3, num_filters, kernel_size=(1, 1))\n",
    "        \n",
    "        self.memory1 = nn.Sequential(self.conv_memory,\n",
    "                                     nn.MaxPool2d(2))\n",
    "        \n",
    "        self.memory2 = nn.Sequential(self.conv_memory,\n",
    "                                     nn.MaxPool2d(4))\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_filters * 4 * 4, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.max_pool2d((self.res(out) + self.conv_memory(x)), 2)\n",
    "        out = F.max_pool2d((self.res(out) + self.memory1(x)), 2)\n",
    "        out = F.max_pool2d((self.res(out) + self.memory2(x)), 2)\n",
    "        out = out.reshape(-1, self.num_filters * 4 *4)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = ResNet(8, 3).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An_asus\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \t loss: 0.05122611243605614\n",
      "epoch: 5 \t loss: 0.035530791873931884\n",
      "epoch: 10 \t loss: 0.031444659615159035\n",
      "epoch: 15 \t loss: 0.029040825434923173\n",
      "epoch: 20 \t loss: 0.027298846329450607\n",
      "epoch: 25 \t loss: 0.026026308337450028\n",
      "epoch: 30 \t loss: 0.025165295752882958\n",
      "epoch: 35 \t loss: 0.024436747311353684\n",
      "epoch: 40 \t loss: 0.023795349410772323\n",
      "epoch: 45 \t loss: 0.023388135784864424\n",
      "epoch: 50 \t loss: 0.02284540410399437\n"
     ]
    }
   ],
   "source": [
    "res_optimizer = optim.Adam(res_model.parameters(), lr=1e-3)\n",
    "\n",
    "training_loop(n_epochs = 50,\n",
    "              optimizer = res_optimizer,\n",
    "              model = res_model,\n",
    "              loss_fn = loss_fn,\n",
    "              train_loader= train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_predictions: 6808 / 10000 \t accuracy: 0.6807999610900879\n"
     ]
    }
   ],
   "source": [
    "test_loop(model=res_model, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConv(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super(ResConv, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(filters, filters, kernel_size=(3, 3), padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.conv(x))\n",
    "        return (out + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryNet(nn.Module):\n",
    "    def __init__(self, num_filters, num_blocks):\n",
    "        super(MemoryNet, self).__init__()\n",
    "        self.num_filters = num_filters\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, num_filters, kernel_size=(3, 3), padding=1)\n",
    "\n",
    "        self.res = nn.Sequential( * ( num_blocks * [ResConv(num_filters)]))\n",
    "        \n",
    "        self.conv_memory = nn.Conv2d(3, num_filters, kernel_size=(1, 1))\n",
    "        \n",
    "        self.memory1 = nn.Sequential(self.conv_memory,\n",
    "                                     nn.MaxPool2d(2))\n",
    "        \n",
    "        self.memory2 = nn.Sequential(self.conv_memory,\n",
    "                                     nn.MaxPool2d(4))\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_filters * 4 * 4, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.conv1(x))\n",
    "        out = F.max_pool2d((self.res(out) + self.conv_memory(x)), 2)\n",
    "        out = F.max_pool2d((self.res(out) + self.memory1(x)), 2)\n",
    "        out = F.max_pool2d((self.res(out) + self.memory2(x)), 2)\n",
    "        out = out.reshape(-1, self.num_filters * 4 *4)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \t loss: 0.05032935439944267\n",
      "epoch: 5 \t loss: 0.03129648393690586\n",
      "epoch: 10 \t loss: 0.026305621837377547\n",
      "epoch: 15 \t loss: 0.023850160502195357\n",
      "epoch: 20 \t loss: 0.022230680535435678\n",
      "epoch: 25 \t loss: 0.02104149684280157\n",
      "epoch: 30 \t loss: 0.020186014511287213\n",
      "epoch: 35 \t loss: 0.019479490060806275\n",
      "epoch: 40 \t loss: 0.01889821978479624\n",
      "epoch: 45 \t loss: 0.018417731516957282\n",
      "epoch: 50 \t loss: 0.01794390323251486\n"
     ]
    }
   ],
   "source": [
    "mem_model = MemoryNet(16, 3).to('cuda')\n",
    "\n",
    "mem_optimizer = optim.Adam(mem_model.parameters(), lr=1e-3)\n",
    "\n",
    "training_loop(n_epochs = 50,\n",
    "              optimizer = mem_optimizer,\n",
    "              model = mem_model,\n",
    "              loss_fn = loss_fn,\n",
    "              train_loader= train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_predictions: 6982 / 10000 \t accuracy: 0.698199987411499\n"
     ]
    }
   ],
   "source": [
    "test_loop(model=mem_model, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
