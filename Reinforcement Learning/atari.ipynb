{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0222f8dd-360b-492f-acad-d9099e17d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import torch\n",
    "import copy\n",
    "import tqdm\n",
    "import time\n",
    "import gc\n",
    "import cv2\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13a390d-1110-4614-be72-d5d3c81e52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"ALE/SpaceInvaders-v5\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48fd98ea-bffe-41e6-af9f-d5ac44c41b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An_asus\\anaconda3\\envs\\reinforcement-learning\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n"
     ]
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(500):\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "    n_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    frame = env.render()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    frame = cv2.resize(frame, (320, 420))\n",
    "    frame = cv2.putText(frame, f'Action taken: {action}  Reward: {reward}', (10, 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA) \n",
    "    cv2.imshow(\"gameplay\", frame)\n",
    "    pressedKey = cv2.waitKey(60) & 0xFF\n",
    "    if pressedKey == ord('q'):\n",
    "        break\n",
    "        \n",
    "    total_reward += reward\n",
    "    if terminated or truncated:\n",
    "            break\n",
    "        \n",
    "    state = n_state\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335250b5-b1e6-483b-a501-62dc3811a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img, size=(84, 84)):\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageOps.grayscale(img).resize((size[0], size[1]))\n",
    "    img = np.array(img)\n",
    "    return torch.tensor(img, dtype=torch.float) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5802a3-61e9-407b-8ce1-a19e5a98cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self, in_dim=1, out_dim=env.action_space.n):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv_net = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_dim, 4, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(4, 8, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(8, 16, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1024, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv_net(x)\n",
    "        flattened = torch.flatten(conv_out, start_dim=1)\n",
    "        fc_out = self.fc(flattened)\n",
    "        return torch.nn.functional.softmax(fc_out, dim=1)\n",
    "        #return fc_out\n",
    "\n",
    "    def act(self, x):\n",
    "        probs = self.forward(x)\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "        return action.item(), m.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a34a5434-756d-4b8c-9dc4-c1e60ef5ce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e08519-c6e1-493e-a511-c058d24d0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQN().to(DEVICE)\n",
    "target_dqn = copy.deepcopy(dqn).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03bd776c-860b-413f-baa6-4170fb6012d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265446\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in target_dqn.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe001b1-6c17-45e8-aa3e-d25be5bcce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.05\n",
    "decay_rate = 0.005\n",
    "n_episodes = 1000\n",
    "max_steps = 500\n",
    "gamma = 0.95\n",
    "alpha = 0.01\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(dqn.parameters(), lr=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4492cb81-a9bc-4cf0-9c1d-fa54bfeea53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa298dc-ed12-47c8-b87c-1f280087a9bc",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "399d8829-19c8-4477-8258-a04aa43f3597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]C:\\Users\\An_asus\\anaconda3\\envs\\reinforcement-learning\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  3%|██▏                                                                           | 28/1000 [02:27<1:25:37,  5.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m processed_new_state \u001b[38;5;241m=\u001b[39m process_image(n_state)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 18\u001b[0m     _, target_probs \u001b[38;5;241m=\u001b[39m target_dqn\u001b[38;5;241m.\u001b[39mact(processed_new_state)\n\u001b[0;32m     19\u001b[0m     target \u001b[38;5;241m=\u001b[39m reward \u001b[38;5;241m+\u001b[39m gamma\u001b[38;5;241m*\u001b[39mtarget_probs\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(log_probs, target)\n",
      "Cell \u001b[1;32mIn[38], line 32\u001b[0m, in \u001b[0;36mDQN.act\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[0;32m     31\u001b[0m m \u001b[38;5;241m=\u001b[39m Categorical(probs)\n\u001b[1;32m---> 32\u001b[0m action \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mitem(), m\u001b[38;5;241m.\u001b[39mlog_prob(action)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\reinforcement-learning\\Lib\\site-packages\\torch\\distributions\\categorical.py:132\u001b[0m, in \u001b[0;36mCategorical.sample\u001b[1;34m(self, sample_shape)\u001b[0m\n\u001b[0;32m    130\u001b[0m     sample_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(sample_shape)\n\u001b[0;32m    131\u001b[0m probs_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events)\n\u001b[1;32m--> 132\u001b[0m samples_2d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(probs_2d, sample_shape\u001b[38;5;241m.\u001b[39mnumel(), \u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples_2d\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in tqdm.tqdm(range(n_episodes)):\n",
    "\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "\n",
    "    state, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    step = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "\n",
    "        processed_state = process_image(state).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "        probs = dqn(processed_state)\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "        n_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        processed_new_state = process_image(n_state).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            target_probs = target_dqn(processed_new_state)\n",
    "            target = reward + gamma*target_probs.max()\n",
    "\n",
    "        loss = loss_fn(probs, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    \n",
    "        state = n_state\n",
    "\n",
    "    target_dqn = copy.deepcopy(dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de4c67-78de-4031-95fa-ca10a0e6f425",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84a9b0ec-4cbd-4b98-abb6-e4bbfde48c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.load_state_dict(torch.load(\"dqn space invaders.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf8e5a0-ec42-4e02-9d5e-96f6414ddb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv_net): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): ReLU()\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89366186-1584-4e8c-a50a-5ea51881fa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.0\n"
     ]
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "terminated = False\n",
    "truncated = False\n",
    "step = 0\n",
    "\n",
    "episode_reward = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    processed_state = process_image(state).unsqueeze(0).unsqueeze(0)#.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out_ids = dqn(processed_state)\n",
    "    m = Categorical(out_ids)\n",
    "    action = m.sample()\n",
    "    n_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    frame = env.render()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    frame = cv2.resize(frame, (320, 420))\n",
    "    frame = cv2.putText(frame, f'Action taken: {action}  Reward: {reward}', (10, 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    cv2.imshow(\"gameplay\", frame)\n",
    "    pressedKey = cv2.waitKey(60) & 0xFF\n",
    "    if pressedKey == ord('q'):\n",
    "        break\n",
    "\n",
    "    episode_reward += reward\n",
    "\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "    state = n_state\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bf0d1ef-e7f7-4f8b-8d87-d9d821103d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward mean: 100.000 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "print(f\"reward mean: {reward_mean:.3f} +/- {reward_std:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
